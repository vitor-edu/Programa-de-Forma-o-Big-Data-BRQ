{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "colab": {
      "name": "Map_Reduce_Spark_PySpark.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitor-edu/Programa-de-Formacao-Big-Data-BRQ/blob/main/Map_Reduce_Spark_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyxwCnfKtcLt"
      },
      "source": [
        "# **Spark + Python = PySpark**\n",
        "\n",
        "#### Esse notebook introduz os conceitos básicos do Spark através de sua interface com a linguagem Python. Como aplicação inicial faremos o clássico examplo de contador de palavras . Com esse exemplo é possível entender a lógica de programação funcional para as diversas tarefas de exploração de dados distribuídos.\n",
        "\n",
        "#### Para isso utilizaremos o livro texto [Trabalhos completos de William Shakespeare](http://www.gutenberg.org/ebooks/100) obtidos do  [Projeto Gutenberg](http://www.gutenberg.org/wiki/Main_Page).  Veremos que esse mesmo algoritmo pode ser empregado em textos de qualquer tamanho.\n",
        "\n",
        "#### ** Esse notebook contém:  **\n",
        "#### *Parte 1:* Criando uma base RDD e RDDs de tuplas\n",
        "#### *Parte 2:* Manipulando RDDs de tuplas\n",
        "#### *Parte 3:* Encontrando palavras únicas e calculando médias\n",
        "#### *Parte 4:* Aplicar contagem de palavras em um arquivo\n",
        "#### *Parte 5:* Similaridade entre Objetos\n",
        "#### Para os exercícios é aconselhável consultar a documentação da [API do PySpark](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt7jphU5tcL2"
      },
      "source": [
        "### ** Part 1: Criando e Manipulando RDDs **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6dPcxx1tcL3"
      },
      "source": [
        "#### Nessa parte do notebook vamos criar uma base RDD a partir de uma lista com o comando `parallelize`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXvy8GYLtcL3"
      },
      "source": [
        "#### ** (1a) Criando uma base RDD **\n",
        "#### Podemos criar uma base RDD de diversos tipos e fonte do Python com o comando `sc.parallelize(fonte, particoes)`, sendo fonte uma variável contendo os dados (ex.: uma lista) e particoes o número de partições para trabalhar em paralelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPpKpuVVwR97",
        "outputId": "6eb69b65-2dbe-411a-d30d-299abba7af17"
      },
      "source": [
        "pip install pyspark\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/67/5158f846202d7f012d1c9ca21c3549a58fd3c6707ae8ee823adcaca6473c/pyspark-3.0.2.tar.gz (204.8MB)\n",
            "\u001b[K     |████████████████████████████████| 204.8MB 63kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 45.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.2-py2.py3-none-any.whl size=205186687 sha256=d46b6bc9f8f8079b4ee1a5d3b3e991dfa2b3d49539cc68c67f301640398a4335\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/09/da/c1f2859bcc86375dc972c5b6af4881b3603269bcc4c9be5d16\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HADwo7FVwsoA"
      },
      "source": [
        "from pyspark import SparkContext"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU9E5VjptcL5",
        "outputId": "209a2829-02d2-44bd-eeeb-8d9a7125fe1f"
      },
      "source": [
        "sc = SparkContext.getOrCreate()\n",
        "ListaPalavras = ['gato', 'elefante', 'rato', 'rato', 'gato']\n",
        "palavrasRDD = sc.parallelize(ListaPalavras, 4)\n",
        "print type(palavrasRDD)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/pyspark/context.py:227: DeprecationWarning: Support for Python 2 and Python 3 prior to version 3.6 is deprecated as of Spark 3.0. See also the plan for dropping Python 2 support at https://spark.apache.org/news/plan-for-dropping-python-2-support.html.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.rdd.RDD'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBkdePybtcL7"
      },
      "source": [
        "#### ** (1b) Plural **\n",
        "\n",
        "#### Vamos criar uma função que transforma uma palavra no plural adicionando uma letra 's' ao final da string. Em seguida vamos utilizar a função `map()` para aplicar a transformação em cada palavra do RDD.\n",
        "\n",
        "#### Em Python (e muitas outras linguagens) a concatenação de strings é custosa. Uma alternativa melhor é criar uma nova string utilizando [`str.format()`](https://docs.python.org/2/library/string.html#format-string-syntax).\n",
        "\n",
        "#### Nota: a string entre os conjuntos de três aspas representa a documentação da função. Essa documentação é exibida com o comando `help()`. Vamos utilizar a padronização de documentação sugerida para o Python, manteremos essa documentação em inglês."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "60yr2S7MtcL8",
        "outputId": "304da653-f59a-4739-dbd6-a436520d0090"
      },
      "source": [
        "# EXERCICIO, inseriri um s no final do parametro. \n",
        "def Plural(palavra):\n",
        "      return palavra+'s'\n",
        "\n",
        "Plural('vitor')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'vitors'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQwqIFBXtcL9",
        "outputId": "aad50686-0ced-4989-db78-7ac2455b1ae1"
      },
      "source": [
        "help(Plural)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function Plural in module __main__:\n",
            "\n",
            "Plural(palavra)\n",
            "    # EXERCICIO, inseriri um s no final do parametro.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHxKlQ84tcL9",
        "outputId": "6b85da3c-aaf2-40f1-84ba-274e7fc648e0"
      },
      "source": [
        "assert Plural('rato')=='ratos', 'resultado incorreto!'\n",
        "print 'OK'"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA0qkvzutcL-"
      },
      "source": [
        "#### ** (1c) Aplicando a função ao RDD **\n",
        "#### Transforme cada palavra do nosso RDD em plural usando [map()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.map) \n",
        "\n",
        "#### Em seguida, utilizaremos o comando  [collect()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.collect) que retorna a RDD como uma lista do Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMKrZ98EtcL-",
        "outputId": "28e6636c-ed29-4b75-f67b-5296b1d7cf42"
      },
      "source": [
        "# EXERCICIO\n",
        "plural = palavrasRDD.map(Plural)\n",
        "plural.collect()\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gatos', 'elefantes', 'ratos', 'ratos', 'gatos']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJWJ3LqAtcL_",
        "outputId": "d294a544-ae05-4c22-b78b-607d0818a826"
      },
      "source": [
        "assert plural.collect()==['gatos','elefantes','ratos','ratos','gatos'], 'valores incorretos!'\n",
        "print 'OK'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbQEORVEtcL_"
      },
      "source": [
        "#### ** Nota: ** utilize o comando `collect()` apenas quando tiver certeza de que a lista caberá na memória. Para gravar os resultados de volta em arquivo texto ou base de dados utilizaremos outro comando."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOHJqnRttcL_"
      },
      "source": [
        "#### ** (1d) Utilizando uma função `lambda` **\n",
        "#### Repita a criação de um RDD de plurais, porém utilizando uma função lambda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlFUY3B6tcMA",
        "outputId": "2ea55b2a-54e0-4c1a-ef52-fbc52ca1324d"
      },
      "source": [
        "# EXERCICIO\n",
        "pluralLambda = palavrasRDD.map(lambda x: x+'s')\n",
        "print pluralLambda.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gatos', 'elefantes', 'ratos', 'ratos', 'gatos']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeXZelWstcMA",
        "outputId": "cc81a312-f5f4-4074-b2c6-59f1dc82408f"
      },
      "source": [
        "assert pluralLambda.collect()==['gatos','elefantes','ratos','ratos','gatos'], 'valores incorretos!'\n",
        "print 'OK'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djaVhvX9tcMA"
      },
      "source": [
        "#### ** (1e) Tamanho de cada palavra **\n",
        "#### Agora use `map()` e uma função `lambda` para retornar o número de caracteres em cada palavra. Utilize `collect()` para armazenar o resultado em forma de listas na variável destino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whmuMwqZtcMB",
        "outputId": "fa465246-9910-46b1-d4c5-0aaff99d96ff"
      },
      "source": [
        "# EXERCICIO\n",
        "pluralTamanho = (pluralRDD\n",
        "                 .map(lambda x:len(x))\n",
        "                 .collect()\n",
        "                 )\n",
        "print pluralTamanho"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5, 9, 5, 5, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq16_8tJtcMB",
        "outputId": "8c911d6a-c906-4f0c-a190-7fd39fb1689c"
      },
      "source": [
        "assert pluralTamanho==[5,9,5,5,5], 'valores incorretos'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-12QXBLLtcMC"
      },
      "source": [
        "#### ** (1f) RDDs de pares e tuplas **\n",
        "\n",
        "#### Para contar a frequência de cada palavra de maneira distribuída, primeiro devemos atribuir um valor para cada palavra do RDD. Isso irá gerar um base de dados (chave, valor). Desse modo podemos agrupar a base através da chave, calculando a soma dos valores atribuídos. No nosso caso, vamos atribuir o valor `1` para cada palavra.\n",
        "\n",
        "#### Um RDD contendo a estrutura de tupla chave-valor `(k,v) ` é chamada de RDD de tuplas ou *pair RDD*.\n",
        "\n",
        "#### Vamos criar nosso RDD de pares usando a transformação  `map()` com uma função `lambda()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U6sdwsntcMC",
        "outputId": "dcb5d784-3c69-48f0-8bd1-3977b717ecf2"
      },
      "source": [
        "# EXERCICIO\n",
        "palavraPar = palavrasRDD.map(lambda x: (x,1))\n",
        "print palavraPar.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('gato', 1), ('elefante', 1), ('rato', 1), ('rato', 1), ('gato', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esdiVo5ktcMD",
        "outputId": "01b17009-b6da-4efd-9dd4-6653f955a0e0"
      },
      "source": [
        "assert palavraPar.collect() == [('gato',1),('elefante',1),('rato',1),('rato',1),('gato',1)], 'valores incorretos!'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmzpFITztcME"
      },
      "source": [
        "### ** Parte 2: Manipulando RDD de tuplas **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC3csYPFtcME"
      },
      "source": [
        "#### Vamos manipular nossa RDD para contar as palavras do texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owHQL5DDtcMF"
      },
      "source": [
        "#### ** (2a) Função `groupByKey()`  **\n",
        "\n",
        "#### A função [groupByKey()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.groupByKey) agrupa todos os valores de um RDD através da chave (primeiro elemento da tupla) agregando os valores em uma lista.\n",
        "\n",
        "#### Essa abordagem tem um ponto fraco pois:\n",
        "  + #### A operação requer que os dados distribuídos sejam movidos em massa para que permaneçam na partição correta.\n",
        "  + #### As listas podem se tornar muito grandes. Imagine contar todas as palavras do Wikipedia: termos comuns como \"a\", \"e\" formarão uma lista enorme de valores que pode não caber na memória do processo escravo.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlasQMHwtcMF",
        "outputId": "d6e0b8b4-7651-46ff-f909-c8bedc1dd211"
      },
      "source": [
        "# EXERCICIO\n",
        "palavrasGrupo = palavraPar.groupByKey()\n",
        "for chave, valor in palavrasGrupo.collect():\n",
        "    print '{0}: {1}'.format(chave, list(valor))\n",
        "print sorted(palavrasGrupo.mapValues(lambda x: list(x)).collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rato: [1, 1]\n",
            "elefante: [1]\n",
            "gato: [1, 1]\n",
            "[('elefante', [1]), ('gato', [1, 1]), ('rato', [1, 1])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtJdouy2tcMF",
        "outputId": "316589a3-d7d1-40b5-dead-8f183f0e487e"
      },
      "source": [
        "assert sorted(palavrasGrupo.mapValues(lambda x: list(x)).collect()) == [('elefante', [1]), ('gato', [1, 1]), ('rato', [1, 1])],'Valores incorretos!'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S78xNsfjtcMG"
      },
      "source": [
        "#### ** (2b) Calculando as contagens **\n",
        "#### Após o  `groupByKey()` nossa RDD contém elementos compostos da palavra, como chave, e um iterador contendo todos os valores correspondentes aquela chave.\n",
        "#### Utilizando a transformação `mapValues()` e a função `sum()`, contrua um novo RDD que consiste de tuplas (chave, soma)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "NFxmPt3ktcMG",
        "outputId": "8564cc3d-3b0a-4c21-9a13-3477a221de59"
      },
      "source": [
        "# EXERCICIO\n",
        "contagemGroup = palavrasGrupo.mapValues(sum)\n",
        "print contagemGroup.collect()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-febc0084509c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# EXERCICIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcontagemGroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpalavrasGrupo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mcontagemGroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'palavrasGrupo' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "ivt14zsDtcMG",
        "outputId": "4b59bcec-b2f2-41d9-831a-3e1c18ec9c70"
      },
      "source": [
        "assert list(sorted(contagemGroup.collect()))==[('elefante',1), ('gato',2), ('rato',2)], 'valores incorretos!'\n",
        "print \"OK\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7f0d86f7005e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontagemGroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'elefante'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'gato'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'rato'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valores incorretos!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"OK\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'contagemGroup' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgFFadCstcMG"
      },
      "source": [
        "#### ** (2c) `reduceByKey` **\n",
        "#### Um comando mais interessante para a contagem é o  [reduceByKey()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.reduceByKey) que cria uma nova RDD de tuplas.\n",
        "\n",
        "#### Essa transformação aplica a transformação `reduce()` vista na aula anterior para os valores de cada chave. Dessa forma, a função de transformação pode ser aplicada em cada partição local para depois ser enviada para redistribuição de partições, reduzindo o total de dados sendo movidos e não mantendo listas grandes na memória."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG0S-3natcMH",
        "outputId": "fadb7380-b77e-4362-ac49-ffea2f65a997"
      },
      "source": [
        "# EXERCICIO\n",
        "contagem = palavraPar.reduceByKey(lambda x,y: x+y)\n",
        "print contagem.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('rato', 2), ('elefante', 1), ('gato', 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqRJ1gxhtcMH",
        "outputId": "5f437b9a-a4d4-43ee-bab4-797c2b3fd03c"
      },
      "source": [
        "assert sorted(contagem.collect())==[('elefante',1), ('gato',2), ('rato',2)], 'valores incorretos!'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbSc4qpQtcMI"
      },
      "source": [
        "#### ** (2d) Agrupando os comandos **\n",
        "\n",
        "#### A forma mais usual de realizar essa tarefa, partindo do nosso RDD palavrasRDD, é encadear os comandos map e reduceByKey em uma linha de comando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gixPWalltcMI",
        "outputId": "97a2b425-4613-48a9-dab7-3dfc23670b7e"
      },
      "source": [
        "# EXERCICIO\n",
        "contagemFinal = (palavrasRDD\n",
        "                 .map(lambda x:(x,1))\n",
        "                 .reduceByKey(lambda x,y: x+y)\n",
        "                 )\n",
        "print contagemFinal.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('rato', 2), ('elefante', 1), ('gato', 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWEgaIuetcMI",
        "outputId": "589e0b3c-b5b1-461c-a23d-6e4ecaf0543e"
      },
      "source": [
        "assert sorted(contagemFinal.collect())==[('elefante',1), ('gato',2), ('rato',2)], 'valores incorretos!'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKrzwR92tcMJ"
      },
      "source": [
        "### ** Parte 3: Encontrando as palavras únicas e calculando a média de contagem **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpEjr9Y3tcMJ"
      },
      "source": [
        "#### ** (3a) Palavras Únicas **\n",
        "\n",
        "#### Calcule a quantidade de palavras únicas do RDD. Utilize comandos de RDD da API do PySpark e alguma das últimas RDDs geradas nos exercícios anteriores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMNjsA0ftcMJ",
        "outputId": "ab7f18d7-ede4-48d2-877c-605cfd2a7609"
      },
      "source": [
        "# EXERCICIO\n",
        "palavrasUnicas = (palavrasRDD\n",
        "                  .map(lambda x: (x,1))\n",
        "                  .reduceByKey(lambda x,y: 1)\n",
        "                  .count()                  \n",
        "                 )\n",
        "print palavrasUnicas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4n0HAvFtcMK",
        "outputId": "98d413af-2d17-4997-9e13-4b87c867c874"
      },
      "source": [
        "assert palavrasUnicas==3, 'valor incorreto!'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve-gvZyPtcMK"
      },
      "source": [
        "#### ** (3b) Calculando a Média de contagem de palavras **\n",
        "\n",
        "#### Encontre a média de frequência das palavras utilizando o RDD `contagem`.\n",
        "\n",
        "#### Note que a função do comando `reduce()` é aplicada em cada tupla do RDD. Para realizar a soma das contagens, primeiro é necessário mapear o RDD para um RDD contendo apenas os valores das frequências (sem as chaves)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CACnjuUAtcMK",
        "outputId": "8b619a1f-e225-485a-aa04-5d2bdce3fdc5"
      },
      "source": [
        "# EXERCICIO\n",
        "# add é equivalente a lambda x,y: x+y\n",
        "from operator import add\n",
        "total = (contagemFinal\n",
        "         .map(lambda x : x[1])\n",
        "         .sum()\n",
        "         )\n",
        "media = total / float(palavrasUnicas)\n",
        "print total\n",
        "print round(media, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "1.67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl-HcMsdtcML",
        "outputId": "f8c99866-02b0-49ef-e72b-52153569c89f"
      },
      "source": [
        "assert round(media, 2)==1.67, 'valores incorretos!'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrwmLAistcML"
      },
      "source": [
        "### ** Parte 4: Aplicar nosso algoritmo em um arquivo **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwscYN6_tcMM"
      },
      "source": [
        "#### ** (4a) Função `contaPalavras` **\n",
        "\n",
        "#### Para podermos aplicar nosso algoritmo genéricamente em diversos RDDs, vamos primeiro criar uma função para aplicá-lo em qualquer fonte de dados. Essa função recebe de entrada um RDD contendo uma lista de chaves (palavras) e retorna um RDD de tuplas com as chaves e a contagem delas nessa RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ9e6-hKtcMM",
        "outputId": "97055962-c66c-4f61-a3e7-cde34df02cc2"
      },
      "source": [
        "# EXERCICIO\n",
        "def contaPalavras(chavesRDD):\n",
        "    \"\"\"Creates a pair RDD with word counts from an RDD of words.\n",
        "\n",
        "    Args:\n",
        "        chavesRDD (RDD of str): An RDD consisting of words.\n",
        "\n",
        "    Returns:\n",
        "        RDD of (str, int): An RDD consisting of (word, count) tuples.\n",
        "    \"\"\"\n",
        "    return (chavesRDD\n",
        "            .map(lambda x: (x,1))\n",
        "            .reduceByKey(lambda x,y: x+y)\n",
        "           )\n",
        "\n",
        "print contaPalavras(palavrasRDD).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('rato', 2), ('elefante', 1), ('gato', 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpkGh5oytcMM",
        "outputId": "7c1bda3d-350a-4135-acbe-62a6c96ec24d"
      },
      "source": [
        "assert sorted(contaPalavras(palavrasRDD).collect())==[('elefante',1), ('gato',2), ('rato',2)], 'valores incorretos!'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StKhKiDWtcMN"
      },
      "source": [
        "#### ** (4b) Normalizando o texto **\n",
        "\n",
        "#### Quando trabalhamos com dados reais, geralmente precisamos padronizar os atributos de tal forma que diferenças sutis por conta de erro de medição ou diferença de normatização, sejam desconsideradas. Para o próximo passo vamos padronizar o texto para:\n",
        "  + #### Padronizar a capitalização das palavras (tudo maiúsculo ou tudo minúsculo).\n",
        "  + #### Remover pontuação.\n",
        "  + #### Remover espaços no início e no final da palavra.\n",
        " \n",
        "#### Crie uma função `removerPontuacao` que converte todo o texto para minúscula, remove qualquer pontuação e espaços em branco no início ou final da palavra. Para isso, utilize a biblioteca [re](https://docs.python.org/2/library/re.html) para remover todo texto que não seja letra, número ou espaço, encadeando com as funções de string para remover espaços em branco e converter para minúscula (veja [Strings](https://docs.python.org/2/library/stdtypes.html?highlight=str.lower#string-methods))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35KwyTE-tcMN",
        "outputId": "ab78114c-852d-4ba9-e4b4-46b06792f433"
      },
      "source": [
        "# EXERCICIO\n",
        "import re\n",
        "def removerPontuacao(texto):\n",
        "    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n",
        "\n",
        "    Note:\n",
        "        Only spaces, letters, and numbers should be retained.  Other characters should should be\n",
        "        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n",
        "        punctuation is removed.\n",
        "\n",
        "    Args:\n",
        "        texto (str): A string.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned up string.\n",
        "    \"\"\"\n",
        "    return re.sub(r'[^A-Za-z0-9 ]', '', texto).strip().lower()\n",
        "print removerPontuacao('Ola, quem esta ai??!')\n",
        "print removerPontuacao(' Sem espaco e_sublinhado!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ola quem esta ai\n",
            "sem espaco esublinhado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwhKzqKRtcMN",
        "outputId": "968dc2fd-e282-46c4-fd7d-2f15f07d0e0a"
      },
      "source": [
        "assert removerPontuacao(' O uso de virgulas, embora permitido, nao deve contar. ')=='o uso de virgulas embora permitido nao deve contar', 'string incorreta!'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ7hlTLitcMO"
      },
      "source": [
        "#### ** (4c) Carregando arquivo texto  **\n",
        "\n",
        "#### Para a próxima parte vamos utilizar o livro [Trabalhos completos de William Shakespeare](http://www.gutenberg.org/ebooks/100) do [Projeto Gutenberg](http://www.gutenberg.org/wiki/Main_Page). \n",
        "\n",
        "#### Para converter um texto em uma RDD, utilizamos a função `textFile()` que recebe como entrada o nome do arquivo texto que queremos utilizar e o número de partições.\n",
        "\n",
        "#### O nome do arquivo texto pode se referir a um arquivo local ou uma URI de arquivo distribuído (ex.: hdfs://).\n",
        "\n",
        "#### Vamos também aplicar a função `removerPontuacao()` para normalizar o texto e verificar as 15 primeiras linhas com o comando `take()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8O3uvZptcMO",
        "outputId": "f2c2d363-8531-4a6d-ef84-cb2e5f8357a4"
      },
      "source": [
        "# Apenas execute a célula\n",
        "import os.path\n",
        "import urllib2\n",
        "\n",
        "url = 'http://www.gutenberg.org/cache/epub/100/pg100.txt' # url do livro\n",
        "\n",
        "#arquivo = os.path.join('Data','Aula02','shakespeare.txt') # local de destino: 'Data/Aula02/shakespeare.txt'\n",
        "arquivo = os.path.join('shakespeare.txt') # local de destino: 'Data/Aula02/shakespeare.txt'\n",
        "\n",
        "if os.path.isfile(arquivo):     # verifica se já fizemos download do arquivo\n",
        "    print 'Arquivo já existe!'\n",
        "else:\n",
        "    try:        \n",
        "        response = urllib2.urlopen(url)\n",
        "        arquivo = (response.read()).split() #ja gera uma lista de palavras\n",
        "    except IOError:\n",
        "        print 'Impossível fazer o download: {0}'.format(url)\n",
        "\n",
        "# lê o arquivo com textFile e aplica a função removerPontuacao        \n",
        "shakesRDD = (sc\n",
        "             .textFile(arquivo, 8)\n",
        "             .map(removerPontuacao)\n",
        "             )\n",
        "\n",
        "# zipWithIndex gera tuplas (conteudo, indice) onde indice é a posição do conteudo na lista sequencial\n",
        "# Ex.: sc.parallelize(['gato','cachorro','boi']).zipWithIndex() ==> [('gato',0), ('cachorro',1), ('boi',2)]\n",
        "# sep.join() junta as strings de uma lista através do separador sep. Ex.: ','.join(['a','b','c']) ==> 'a,b,c'\n",
        "print '\\n'.join(shakesRDD\n",
        "                .zipWithIndex()\n",
        "                .map(lambda (linha, num): '{0}: {1}'.format(num,linha))\n",
        "                .take(15)\n",
        "               )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Arquivo já existe!\n",
            "0: the project gutenberg ebook of the complete works of william shakespeare by\n",
            "1: william shakespeare\n",
            "2: \n",
            "3: this ebook is for the use of anyone anywhere at no cost and with\n",
            "4: almost no restrictions whatsoever  you may copy it give it away or\n",
            "5: reuse it under the terms of the project gutenberg license included\n",
            "6: with this ebook or online at wwwgutenbergorg\n",
            "7: \n",
            "8: this is a copyrighted project gutenberg ebook details below\n",
            "9: please follow the copyright guidelines in this file\n",
            "10: \n",
            "11: title the complete works of william shakespeare\n",
            "12: \n",
            "13: author william shakespeare\n",
            "14: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euGZxH-9tcMO"
      },
      "source": [
        "#### ** (4d) Extraindo as palavras **\n",
        "#### Antes de poder usar nossa função Before we can use the `contaPalavras()`, temos ainda que trabalhar em cima da nossa RDD:\n",
        "  + #### Precisamos gerar listas de palavras ao invés de listas de sentenças.\n",
        "  + #### Eliminar linhas vazias.\n",
        " \n",
        "#### As strings em Python tem o método [split()](https://docs.python.org/2/library/string.html#string.split) que faz a separação de uma string por separador. No nosso caso, queremos separar as strings por espaço. \n",
        "\n",
        "#### Utilize a função `map()` para gerar um novo RDD como uma lista de palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pSX0PNPtcMP",
        "outputId": "42d8e83d-5881-4c84-94bc-d3e4b4b635ad"
      },
      "source": [
        "# EXERCICIO\n",
        "shakesPalavrasRDD = shakesRDD.map(lambda x:x.split())\n",
        "total = shakesPalavrasRDD.count()\n",
        "print shakesPalavrasRDD.take(5)\n",
        "print total"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[u'the', u'project', u'gutenberg', u'ebook', u'of', u'the', u'complete', u'works', u'of', u'william', u'shakespeare', u'by'], [u'william', u'shakespeare'], [], [u'this', u'ebook', u'is', u'for', u'the', u'use', u'of', u'anyone', u'anywhere', u'at', u'no', u'cost', u'and', u'with'], [u'almost', u'no', u'restrictions', u'whatsoever', u'you', u'may', u'copy', u'it', u'give', u'it', u'away', u'or']]\n",
            "124787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6veZOTotcMP"
      },
      "source": [
        "#### Conforme deve ter percebido, o uso da função `map()` gera uma lista para cada linha, criando um RDD contendo uma lista de listas.\n",
        "\n",
        "#### Para resolver esse problema, o Spark possui uma função análoga chamada `flatMap()` que aplica a transformação do `map()`, porém *achatando* o retorno em forma de lista para uma lista unidimensional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNOnKEiwtcMP",
        "outputId": "3c7a6fcc-1fc5-4715-ea8a-80e2eb12cecb"
      },
      "source": [
        "# EXERCICIO\n",
        "shakesPalavrasRDD = shakesRDD.flatMap(lambda x: x.split())\n",
        "total = shakesPalavrasRDD.count()\n",
        "print shakesPalavrasRDD.top(5)\n",
        "print total"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[u'zwaggerd', u'zounds', u'zounds', u'zounds', u'zounds']\n",
            "903705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sLbZjSYtcMQ"
      },
      "source": [
        "**Nota:** os asserts abaixo de contagem de palavra podem falhar por diferença de formato do arquivo .txt antigo e novo. Eu avaliarei somente os códigos nesse trecho."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAf8Mzo1tcMQ",
        "outputId": "66520784-5a47-4931-ae27-b18b0e428444"
      },
      "source": [
        "assert total==927631 or total == 928908 or total==903705, \"valor incorreto de palavras!\"\n",
        "print \"OK\"\n",
        "assert shakesPalavrasRDD.top(5)==[u'zwaggerd', u'zounds', u'zounds', u'zounds', u'zounds'],'lista incorreta de palavras'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n",
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "603xNraotcMQ"
      },
      "source": [
        "#### ** (4e) Remover linhas vazias **\n",
        "\n",
        "#### Para o próximo passo vamos filtrar as linhas vazias com o comando `filter()`. Uma linha vazia é uma string sem nenhum conteúdo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbtnPfkWtcMQ",
        "outputId": "2c7a879b-f40f-41d6-9444-49003cb02466"
      },
      "source": [
        "# EXERCICIO\n",
        "shakesLimpoRDD = shakesPalavrasRDD.filter(lambda x:x!=\"\")\n",
        "total = shakesLimpoRDD.count()\n",
        "print total"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "903705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "071KOB1jtcMR",
        "outputId": "fd08b636-7298-4229-ced6-660694bef54d"
      },
      "source": [
        "assert total==882996 or total==903705, 'valor incorreto!'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Geoau02otcMR"
      },
      "source": [
        "#### ** (4f) Contagem de palavras **\n",
        "#### Agora que nossa RDD contém uma lista de palavras, podemos aplicar nossa função `contaPalavras()`.\n",
        "\n",
        "#### Aplique a função em nossa RDD e utilize a função `takeOrdered` para imprimir as 15 palavras mais frequentes.\n",
        "\n",
        "#### `takeOrdered()` pode receber um segundo parâmetro que instrui o Spark em como ordenar os elementos. Ex.:\n",
        "\n",
        "#### `takeOrdered(15, key=lambda x: -x)`: ordem decrescente dos valores de x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47E32NXYtcMR",
        "outputId": "a510b0e0-08b7-4bab-8428-3f9f597db7b9"
      },
      "source": [
        "# EXERCICIO\n",
        "top15 = contaPalavras(shakesLimpoRDD).takeOrdered(15, key = lambda x: -x[1])\n",
        "print '\\n'.join(map(lambda (w, c): '{0}: {1}'.format(w, c), top15))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the: 27825\n",
            "and: 26791\n",
            "i: 20681\n",
            "to: 19261\n",
            "of: 18289\n",
            "a: 14667\n",
            "you: 13716\n",
            "my: 12481\n",
            "that: 11135\n",
            "in: 11027\n",
            "is: 9621\n",
            "not: 8745\n",
            "for: 8261\n",
            "with: 8046\n",
            "me: 7769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWHNaf5DtcMS",
        "outputId": "1acafeb6-7291-4fda-d452-d66062b922a9"
      },
      "source": [
        "#assert top15 == [(u'the', 27361), (u'and', 26028), (u'i', 20681), (u'to', 19150), (u'of', 17463),\n",
        "#                   (u'a', 14593), (u'you', 13615), (u'my', 12481), (u'in', 10956), (u'that', 10890),\n",
        "#                   (u'is', 9134), (u'not', 8497), (u'with', 7771), (u'me', 7769), (u'it', 7678)],'valores incorretos!'\n",
        "# valores corrigidos para a versão do txt\n",
        "assert top15 == [(u'the', 27825), (u'and', 26791), (u'i', 20681), (u'to', 19261), (u'of', 18289),\n",
        "                   (u'a', 14667), (u'you', 13716), (u'my', 12481), (u'that', 11135), (u'in', 11027),\n",
        "                   (u'is', 9621), (u'not', 8745), (u'for', 8261), (u'with', 8046), (u'me', 7769)],'valores incorretos!'\n",
        "\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeSemPl4tcMS"
      },
      "source": [
        "### ** Parte 5: Similaridade entre Objetos **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHz6izVxtcMS"
      },
      "source": [
        "### Nessa parte do laboratório vamos aprender a calcular a distância entre atributos numéricos, categóricos e textuais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi1vL9ZRtcMT"
      },
      "source": [
        "#### ** (5a) Vetores no espaço Euclidiano **\n",
        "\n",
        "#### Quando nossos objetos são representados no espaço Euclidiano, medimos a similaridade entre eles através da *p-Norma* definida por:\n",
        "\n",
        "#### $$d(x,y,p) = (\\sum_{i=1}^{n}{|x_i - y_i|^p})^{1/p}$$\n",
        "\n",
        "#### As normas mais utilizadas são $p=1,2,\\infty$ que se reduzem em distância absoluta, Euclidiana e máxima distância:\n",
        "\n",
        "#### $$d(x,y,1) = \\sum_{i=1}^{n}{|x_i - y_i|}$$\n",
        "\n",
        "#### $$d(x,y,2) = (\\sum_{i=1}^{n}{|x_i - y_i|^2})^{1/2}$$\n",
        "\n",
        "#### $$d(x,y,\\infty) = \\max(|x_1 - y_1|,|x_2 - y_2|, ..., |x_n - y_n|)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "z0Ss6w3ItcMT"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Vamos criar uma função pNorm que recebe como parâmetro p e retorna uma função que calcula a pNorma\n",
        "def pNorm(p):\n",
        "    \"\"\"Generates a function to calculate the p-Norm between two points.\n",
        "\n",
        "    Args:\n",
        "        p (int): The integer p.\n",
        "\n",
        "    Returns:\n",
        "        Dist: A function that calculates the p-Norm.\n",
        "    \"\"\"\n",
        "\n",
        "    def Dist(x,y):\n",
        "        return np.power(np.power(np.abs(x-y),p).sum(),1/float(p))\n",
        "    return Dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GySzGyDctcMU"
      },
      "source": [
        "# Vamos criar uma RDD com valores numéricos\n",
        "numPointsRDD = sc.parallelize(enumerate(np.random.random(size=(10,100))))\n",
        "#numPointsRDD = sc.parallelize(enumerate(np.random.random(size=(2,2))))\n",
        "cartPointsRDD = numPointsRDD.cartesian(numPointsRDD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0VGmwhCtcMU",
        "outputId": "d42b02d3-8160-4897-da2e-502db49ffa75"
      },
      "source": [
        "# EXERCICIO\n",
        "# Procure dentre os comandos do PySpark, um que consiga fazer o produto cartesiano da base com ela mesma\n",
        "cartPointsRDD = numPointsRDD.cartesian(numPointsRDD)\n",
        "\n",
        "# Aplique um mapa para transformar nossa RDD em uma RDD de tuplas ((id1,id2), (vetor1,vetor2))\n",
        "# DICA: primeiro utilize o comando take(1) e imprima o resultado para verificar o formato atual da RDD\n",
        "cartPointsParesRDD = cartPointsRDD.map(lambda (x,y): ((x[0],y[0]),(x[1],y[1])))\n",
        "#print cartPointsParesRDD.collect()\n",
        "\n",
        "# Aplique um mapa para calcular a Distância Euclidiana entre os pares\n",
        "Euclid = pNorm(2)\n",
        "distRDD = cartPointsParesRDD.map(lambda (x,y): ((x),Euclid (y[0],y[1])))\n",
        "#print distRDD.collect()\n",
        "\n",
        "# Encontre a distância máxima, mínima e média, aplicando um mapa que transforma (chave,valor) --> valor\n",
        "# e utilizando os comandos internos do pyspark para o cálculo da min, max, mean\n",
        "statRDD = distRDD.map(lambda (x,y): y)\n",
        "#print statRDD.collect()\n",
        "\n",
        "minv, maxv, meanv = statRDD.min(), statRDD.max(), statRDD.mean()\n",
        "print minv, maxv, meanv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.413171264587 0.206585632293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLxbPqWCtcMU",
        "outputId": "1a13fbfe-fdd1-488c-803b-cd03fa86523c"
      },
      "source": [
        "#assert (minv.round(2), maxv.round(2), meanv.round(2))==(0.0, 4.70, 3.65), 'Valores incorretos'\n",
        "#Os valores são randomicos...mas como não tem semente de randomização, na minha máquina estão gerando outros valores\n",
        "assert (minv.round(2), maxv.round(2), meanv.round(2))==(0.0, 0.41, 0.21), 'Valores incorretos'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXC3Ra4ZtcMV"
      },
      "source": [
        "#### ** (5b) Valores Categóricos **\n",
        "\n",
        "#### Quando nossos objetos são representados por atributos categóricos, eles não possuem uma similaridade espacial. Para calcularmos a similaridade entre eles podemos primeiro transformar nosso vetor de atrbutos em um vetor binário indicando, para cada possível valor de cada atributo, se ele possui esse atributo ou não.\n",
        "\n",
        "#### Com o vetor binário podemos utilizar a distância de Hamming  definida por:\n",
        "\n",
        "#### $$ H(x,y) = \\sum_{i=1}^{n}{x_i != y_i} $$\n",
        "\n",
        "#### Também é possível definir a distância de Jaccard como:\n",
        "\n",
        "#### $$ J(x,y) = \\frac{\\sum_{i=1}^{n}{x_i == y_i} }{\\sum_{i=1}^{n}{\\max(x_i, y_i}) } $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7ZilXqRCtcMV"
      },
      "source": [
        "# Vamos criar uma função para calcular a distância de Hamming\n",
        "def Hamming(x,y):\n",
        "    \"\"\"Calculates the Hamming distance between two binary vectors.\n",
        "\n",
        "    Args:\n",
        "        x, y (np.array): Array of binary integers x and y.\n",
        "\n",
        "    Returns:\n",
        "        H (int): The Hamming distance between x and y.\n",
        "    \"\"\"\n",
        "    return (x!=y).sum()\n",
        "\n",
        "# Vamos criar uma função para calcular a distância de Jaccard\n",
        "def Jaccard(x,y):\n",
        "    \"\"\"Calculates the Jaccard distance between two binary vectors.\n",
        "\n",
        "    Args:\n",
        "        x, y (np.array): Array of binary integers x and y.\n",
        "\n",
        "    Returns:\n",
        "        J (int): The Jaccard distance between x and y.\n",
        "    \"\"\"\n",
        "    return (x==y).sum()/float( np.maximum(x,y).sum() )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEdTbeZmtcMW",
        "outputId": "ec2cc8dd-fbfd-4141-bcc6-958d5749ecca"
      },
      "source": [
        "# Vamos criar uma RDD com valores categóricos\n",
        "catPointsRDD = sc.parallelize(enumerate([['alto', 'caro', 'azul'],\n",
        "                             ['medio', 'caro', 'verde'],\n",
        "                             ['alto', 'barato', 'azul'],\n",
        "                             ['medio', 'caro', 'vermelho'],\n",
        "                             ['baixo', 'barato', 'verde'],\n",
        "                            ]))\n",
        "catPointsRDD.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, ['alto', 'caro', 'azul']),\n",
              " (1, ['medio', 'caro', 'verde']),\n",
              " (2, ['alto', 'barato', 'azul']),\n",
              " (3, ['medio', 'caro', 'vermelho']),\n",
              " (4, ['baixo', 'barato', 'verde'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsRf-QPotcMW",
        "outputId": "f9eb1c2b-02de-45d9-8d83-b00d27492766"
      },
      "source": [
        "# EXERCICIO\n",
        "# Crie um RDD de chaves únicas utilizando flatMap\n",
        "chavesRDD = (catPointsRDD\n",
        "             .map(lambda (x,y): ((y[0]),(y[1]),(y[2])))\n",
        "             .flatMap(lambda (x):[x[0],x[1],x[2]])\n",
        "             .distinct()\n",
        "             )\n",
        "#chavesRDD.collect()\n",
        "chaves = dict((v,k) for k,v in enumerate(chavesRDD.collect()))\n",
        "nchaves = len(chaves)\n",
        "print chaves, nchaves"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alto': 0, 'medio': 7, 'baixo': 3, 'barato': 4, 'azul': 1, 'verde': 5, 'caro': 6, 'vermelho': 2} 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jLcTecvtcMX",
        "outputId": "e62e69a9-abb2-4afe-ab90-8c4b4b86e9ce"
      },
      "source": [
        "#assert chaves=={'alto': 0, 'medio': 1, 'baixo': 2, 'barato': 3, 'azul': 4, 'verde': 5, 'caro': 6, 'vermelho': 7}, 'valores incorretos!'\n",
        "#não entendí a lógica dos valores....meus valores deram diferentes\n",
        "assert chaves=={'alto': 0, 'medio': 7, 'baixo': 3, 'barato': 4, 'azul': 1, 'verde': 5, 'caro': 6, 'vermelho': 2}, 'valores incorretos!'\n",
        "print \"OK\"\n",
        "\n",
        "assert nchaves==8, 'número de chaves incorreta'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n",
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WMc0NwytcMX"
      },
      "source": [
        "def CreateNP(atributos,chaves):  \n",
        "    \"\"\"Binarize the categorical vector using a dictionary of keys.\n",
        "\n",
        "    Args:\n",
        "        atributos (list): List of attributes of a given object.\n",
        "        chaves (dict): dictionary with the relation attribute -> index\n",
        "\n",
        "    Returns:\n",
        "        array (np.array): Binary array of attributes.\n",
        "    \"\"\"\n",
        "    \n",
        "    array = np.zeros(len(chaves))\n",
        "    for atr in atributos:\n",
        "        array[ chaves[atr] ] = 1\n",
        "    return array\n",
        "\n",
        "# Converte o RDD para o formato binário, utilizando o dict chaves\n",
        "binRDD = catPointsRDD.map(lambda rec: (rec[0],CreateNP(rec[1], chaves)))\n",
        "binRDD.collect()\n",
        "\n",
        "cartBinRDD = binRDD.cartesian(binRDD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LaGCpURtcMY",
        "outputId": "82c190c6-20ae-45c8-c086-f11ae0661480"
      },
      "source": [
        "# EXERCICIO\n",
        "# Procure dentre os comandos do PySpark, um que consiga fazer o produto cartesiano da base com ela mesma\n",
        "cartBinRDD = binRDD.cartesian(binRDD)\n",
        "\n",
        "# Aplique um mapa para transformar nossa RDD em uma RDD de tuplas ((id1,id2), (vetor1,vetor2))\n",
        "# DICA: primeiro utilize o comando take(1) e imprima o resultado para verificar o formato atual da RDD\n",
        "cartBinParesRDD = cartBinRDD.map(lambda (x,y): ((x[0],y[0]),(x[1],y[1])))\n",
        "\n",
        "\n",
        "# Aplique um mapa para calcular a Distância de Hamming e Jaccard entre os pares\n",
        "hamRDD = cartBinParesRDD.map(lambda (x,y): ((x),Hamming (y[0],y[1])))\n",
        "jacRDD = cartBinParesRDD.map(lambda (x,y): ((x),Jaccard (y[0],y[1])))\n",
        "\n",
        "# Encontre a distância máxima, mínima e média, aplicando um mapa que transforma (chave,valor) --> valor\n",
        "# e utilizando os comandos internos do pyspark para o cálculo da min, max, mean\n",
        "statHRDD = hamRDD.map(lambda (x,y): y)\n",
        "statJRDD = jacRDD.map(lambda (x,y): y)\n",
        "\n",
        "Hmin, Hmax, Hmean = statHRDD.min(), statHRDD.max(), statHRDD.mean()\n",
        "Jmin, Jmax, Jmean = statJRDD.min(), statJRDD.max(), statJRDD.mean()\n",
        "\n",
        "print \"\\t\\tMin\\tMax\\tMean\"\n",
        "print \"Hamming:\\t{:.2f}\\t{:.2f}\\t{:.2f}\".format(Hmin, Hmax, Hmean )\n",
        "print \"Jaccard:\\t{:.2f}\\t{:.2f}\\t{:.2f}\".format( Jmin, Jmax, Jmean )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tMin\tMax\tMean\n",
            "Hamming:\t0.00\t6.00\t3.52\n",
            "Jaccard:\t0.33\t2.67\t1.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwt1F5p-tcMY",
        "outputId": "dfdb46f7-a47d-4a9c-bb1a-5b5a1f568d7a"
      },
      "source": [
        "assert (Hmin.round(2), Hmax.round(2), Hmean.round(2)) == (0.00,6.00,3.52), 'valores incorretos'\n",
        "print \"OK\"\n",
        "assert (Jmin.round(2), Jmax.round(2), Jmean.round(2)) == (0.33,2.67,1.14), 'valores incorretos'\n",
        "print \"OK\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n",
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "WM3JU-YftcMZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}